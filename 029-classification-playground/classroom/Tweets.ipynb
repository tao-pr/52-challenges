{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "descending-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/pataoengineer/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pataoengineer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-pricing",
   "metadata": {},
   "source": [
    "# 1. Data Preperation & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greenhouse-sustainability",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    }
   ],
   "source": [
    "dfRaw = pd.read_csv(\n",
    "    os.path.join(os.environ['HOME'], 'data', 'tweets', 'training.1600000.processed.noemoticon.csv'),\n",
    "    header=None, usecols=[0,2,4,5], names=['sentiment','date','user','text'],\n",
    "    parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conventional-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment             int64\n",
       "date         datetime64[ns]\n",
       "user                 object\n",
       "text                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "equal-newcastle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:45</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:53</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                date             user  \\\n",
       "0          0 2009-04-06 22:19:45  _TheSpecialOne_   \n",
       "1          0 2009-04-06 22:19:49    scotthamilton   \n",
       "2          0 2009-04-06 22:19:53         mattycus   \n",
       "\n",
       "                                                text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-alberta",
   "metadata": {},
   "source": [
    "## Exploring sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "miniature-madonna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turkish-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1    is upset that he can't update his Facebook by ...\n",
       "2    @Kenichan I dived many times for the ball. Man...\n",
       "3      my whole body feels itchy and like its on fire \n",
       "4    @nationwideclass no, it's not behaving at all....\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw[dfRaw.sentiment==0][:5]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "committed-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000         I LOVE @Health4UandPets u guys r the best!! \n",
       "800001    im meeting up with one of my besties tonight! ...\n",
       "800002    @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003    Being sick can be really cheap when it hurts t...\n",
       "800004      @LovesBrooklyn2 he has that effect on everyone \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw[dfRaw.sentiment==4][:5]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-rescue",
   "metadata": {},
   "source": [
    "## Distribution of most common words in each sentiments\n",
    "By getting rid of following:\n",
    "- mentions\n",
    "- stopwords\n",
    "- symbols\n",
    "- top N common words in both first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "above-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [@switchfoot, http://twitpic.com/2y1zl, -, Aww...\n",
       "1    [is, upset, that, he, can't, update, his, Face...\n",
       "2    [@Kenichan, I, dived, many, times, for, the, b...\n",
       "3    [my, whole, body, feels, itchy, and, like, its...\n",
       "4    [@nationwideclass, no,, it's, not, behaving, a...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWords = dfRaw[dfRaw.columns]\n",
    "dfWords.loc[:,'words'] = dfWords['text'].str.split(' ')\n",
    "dfWords['words'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-bulletin",
   "metadata": {},
   "source": [
    "Clean text by removing stopwords, symbols, and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alpha-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "def clean(ss):\n",
    "    def clean_and_drop(a,b):\n",
    "        def cl(s):\n",
    "            if re.match(r'^\\W+$', s):\n",
    "                return []\n",
    "            elif len(s)>0 and s[0]=='@':\n",
    "                return ['@MENTION']\n",
    "            elif re.match(r'^http\\:w*', s):\n",
    "                return ['@URL']\n",
    "            elif all(['0'<=c<='9' or c in ['.',','] for c in s]):\n",
    "                return ['@NUMBER']\n",
    "            else:\n",
    "                a = re.sub(r'[\\t|,|\\.]','', s)\n",
    "                a = re.sub(r'[\\!]+', ' !', a)\n",
    "                a = re.sub(r'[\\?]+', ' ?', a)\n",
    "                return a.split(' ')\n",
    "        if len(b)==0:\n",
    "            return a\n",
    "        else:\n",
    "            return a + cl(b)\n",
    "    return reduce(clean_and_drop, [[]]+ss)\n",
    "    \n",
    "dfWords.loc[:,'words'] = dfWords['words'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electrical-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@MENTION    783109\n",
       "!           606423\n",
       "to          556733\n",
       "I           498055\n",
       "the         487747\n",
       "a           366409\n",
       "my          280574\n",
       "and         276336\n",
       "i           250770\n",
       "you         243743\n",
       "is          221963\n",
       "for         211048\n",
       "it          209821\n",
       "in          205962\n",
       "of          180215\n",
       "?           173001\n",
       "on          159336\n",
       "@NUMBER     153621\n",
       "me          151411\n",
       "have        133318\n",
       "that        130601\n",
       "so          128602\n",
       "with        112024\n",
       "be          110004\n",
       "but         107809\n",
       "Name: words, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topwords = dfWords['words'].explode()\n",
    "topwords = topwords.value_counts()\n",
    "topwords[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attractive-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@MENTION, !, to, I, the, a, my, and, i, you, is, for, it, in, of, ?, on, @NUMBER, me, have, that, so, with, be, but, at, was, I'm, just, not\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = topwords[:30].reset_index(drop=False)\n",
    "', '.join(stopwords['index'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-grocery",
   "metadata": {},
   "source": [
    "## Clean tweets\n",
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bound-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[@MENTION, @URL, Awww, that's, a, bummer, You,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[is, upset, that, he, can't, update, his, Face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[@MENTION, I, dived, many, times, for, the, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[@MENTION, no, it's, not, behaving, at, all, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>[Just, woke, up, Having, no, school, is, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>[TheWDBcom, Very, cool, to, hear, old, Walt, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>[Are, you, ready, for, your, MoJo, Makeover, ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>[Happy, 38th, Birthday, to, my, boo, of, alll,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>[happy, #charitytuesday, @MENTION, @MENTION, @...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              words\n",
       "0                0  [@MENTION, @URL, Awww, that's, a, bummer, You,...\n",
       "1                0  [is, upset, that, he, can't, update, his, Face...\n",
       "2                0  [@MENTION, I, dived, many, times, for, the, ba...\n",
       "3                0  [my, whole, body, feels, itchy, and, like, its...\n",
       "4                0  [@MENTION, no, it's, not, behaving, at, all, i...\n",
       "...            ...                                                ...\n",
       "1599995          4  [Just, woke, up, Having, no, school, is, the, ...\n",
       "1599996          4  [TheWDBcom, Very, cool, to, hear, old, Walt, i...\n",
       "1599997          4  [Are, you, ready, for, your, MoJo, Makeover, ?...\n",
       "1599998          4  [Happy, 38th, Birthday, to, my, boo, of, alll,...\n",
       "1599999          4  [happy, #charitytuesday, @MENTION, @MENTION, @...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_stopwords(ws):\n",
    "    return [w for w in ws if w not in stopwords]\n",
    "\n",
    "dfClean = dfWords[['sentiment','words']]\n",
    "dfClean.loc[:,'words'] = dfClean['words'].apply(clean_stopwords)\n",
    "dfClean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-civilian",
   "metadata": {},
   "source": [
    "## Check distribution of words in each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eligible-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "newtopwords = dfClean[['words','sentiment']]\n",
    "newtopwords.loc[:, 'cnt'] = 1\n",
    "newtopwords = newtopwords.explode(column='words')\n",
    "newtopwords = newtopwords.groupby(['sentiment','words']).agg('sum').reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "focused-discussion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413566</th>\n",
       "      <td>4</td>\n",
       "      <td>@MENTION</td>\n",
       "      <td>468845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362189</th>\n",
       "      <td>4</td>\n",
       "      <td>!</td>\n",
       "      <td>361363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731701</th>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>248111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727622</th>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "      <td>246624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466221</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>197484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment     words     cnt\n",
       "413566          4  @MENTION  468845\n",
       "362189          4         !  361363\n",
       "731701          4        to  248111\n",
       "727622          4       the  246624\n",
       "466221          4         I  197484"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtopwords[newtopwords.sentiment==4].sort_values(['cnt'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "educated-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41316</th>\n",
       "      <td>0</td>\n",
       "      <td>@MENTION</td>\n",
       "      <td>314264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331751</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>308622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85429</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>300571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>!</td>\n",
       "      <td>245060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327515</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>241123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment     words     cnt\n",
       "41316           0  @MENTION  314264\n",
       "331751          0        to  308622\n",
       "85429           0         I  300571\n",
       "1               0         !  245060\n",
       "327515          0       the  241123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtopwords[newtopwords.sentiment==0].sort_values(['cnt'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-configuration",
   "metadata": {},
   "source": [
    "# 2. Topic Modeling\n",
    "Trying NLP and contextual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-collaboration",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Try term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arctic-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complete-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>[I, LOVE, @MENTION, u, guys, r, the, best, !]</td>\n",
       "      <td>I LOVE @MENTION u guys r the best !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>[im, meeting, up, with, one, of, my, besties, ...</td>\n",
       "      <td>im meeting up with one of my besties tonight !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, Thanks, for, the, Twitter, add, Sun...</td>\n",
       "      <td>@MENTION Thanks for the Twitter add Sunisa ! I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>[Being, sick, can, be, really, cheap, when, it...</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, he, has, that, effect, on, everyone]</td>\n",
       "      <td>@MENTION he has that effect on everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800005</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, You, can, tell, him, that, I, just,...</td>\n",
       "      <td>@MENTION You can tell him that I just burst ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800006</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, Thans, for, your, response, Ihad, a...</td>\n",
       "      <td>@MENTION Thans for your response Ihad already ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800007</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, I, am, so, jealous, hope, you, had,...</td>\n",
       "      <td>@MENTION I am so jealous hope you had a great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800008</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, ah, congrats, mr, fletcher, for, fi...</td>\n",
       "      <td>@MENTION ah congrats mr fletcher for finally j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800009</th>\n",
       "      <td>4</td>\n",
       "      <td>[@MENTION, I, RESPONDED, Stupid, cat, is, help...</td>\n",
       "      <td>@MENTION I RESPONDED Stupid cat is helping me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                              words  \\\n",
       "800000          4      [I, LOVE, @MENTION, u, guys, r, the, best, !]   \n",
       "800001          4  [im, meeting, up, with, one, of, my, besties, ...   \n",
       "800002          4  [@MENTION, Thanks, for, the, Twitter, add, Sun...   \n",
       "800003          4  [Being, sick, can, be, really, cheap, when, it...   \n",
       "800004          4    [@MENTION, he, has, that, effect, on, everyone]   \n",
       "800005          4  [@MENTION, You, can, tell, him, that, I, just,...   \n",
       "800006          4  [@MENTION, Thans, for, your, response, Ihad, a...   \n",
       "800007          4  [@MENTION, I, am, so, jealous, hope, you, had,...   \n",
       "800008          4  [@MENTION, ah, congrats, mr, fletcher, for, fi...   \n",
       "800009          4  [@MENTION, I, RESPONDED, Stupid, cat, is, help...   \n",
       "\n",
       "                                                     text  \n",
       "800000                I LOVE @MENTION u guys r the best !  \n",
       "800001  im meeting up with one of my besties tonight !...  \n",
       "800002  @MENTION Thanks for the Twitter add Sunisa ! I...  \n",
       "800003  Being sick can be really cheap when it hurts t...  \n",
       "800004            @MENTION he has that effect on everyone  \n",
       "800005  @MENTION You can tell him that I just burst ou...  \n",
       "800006  @MENTION Thans for your response Ihad already ...  \n",
       "800007  @MENTION I am so jealous hope you had a great ...  \n",
       "800008  @MENTION ah congrats mr fletcher for finally j...  \n",
       "800009  @MENTION I RESPONDED Stupid cat is helping me ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfClean[['sentiment','words']]\n",
    "df.loc[:,'text'] = df['words'].apply(lambda xs: ' '.join(xs))\n",
    "df[df.sentiment == 4][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "constant-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000, 160000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain, dfTest = train_test_split(df, test_size=0.1)\n",
    "len(dfTrain), len(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "distinguished-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectoriser(ngram=(1,1), min_df=0.0, max_df=1.0):\n",
    "    return TfidfVectorizer(\n",
    "        lowercase=True, ngram_range=ngram, min_df=min_df, max_df=max_df,\n",
    "        max_features=10000)\n",
    "\n",
    "pipesTfidf = {\n",
    "    \"logit\": make_pipeline(vectoriser(ngram=(1,2)), LogisticRegression()),\n",
    "    \"logit-3gram\": make_pipeline(vectoriser(ngram=(1,3)), LogisticRegression()),\n",
    "    #\"sgsvc\": make_pipeline(vectoriser(ngram=(1,2)), \n",
    "    #    SGDClassifier(loss='hinge', max_iter=200, penalty='l2', n_jobs=3)),\n",
    "    \"randomforest\": make_pipeline(vectoriser(ngram=(1,2)), RandomForestClassifier(\n",
    "        n_estimators=25, max_depth=10, n_jobs=3\n",
    "    ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "identical-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : logit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : logit-3gram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pataoengineer/opt/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : randomforest\n"
     ]
    }
   ],
   "source": [
    "def train(m, p):\n",
    "    print(f'Training : {m}')\n",
    "    return p.fit(X=dfTrain['text'], y=dfTrain['sentiment'])\n",
    "\n",
    "tfidfModels = {m: train(m, p) for m,p in pipesTfidf.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-fluid",
   "metadata": {},
   "source": [
    "Validating the TFIDF-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rational-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "overall-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of logit = 0.89\n",
      "AUC of logit-3gram = 0.88\n",
      "AUC of randomforest = 0.76\n"
     ]
    }
   ],
   "source": [
    "for m,p in tfidfModels.items():\n",
    "    pred = p.predict_proba(dfTest['text'])\n",
    "    score = roc_auc_score(dfTest['sentiment'], pred[:,1])\n",
    "    print(f'AUC of {m} = {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-tenant",
   "metadata": {},
   "source": [
    "Test the models in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comic-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit : correct positive = 86, correct_negative = 76\n",
      "logit-3gram : correct positive = 84, correct_negative = 76\n",
      "randomforest : correct positive = 64, correct_negative = 73\n"
     ]
    }
   ],
   "source": [
    "positives = dfTest[dfTest.sentiment==4].sample(n=100)\n",
    "negatives = dfTest[dfTest.sentiment==0].sample(n=100)\n",
    "for m,p in tfidfModels.items():\n",
    "    pred_pos = p.predict(positives['text'])\n",
    "    pred_neg = p.predict(negatives['text'])\n",
    "    n_correct_pos = len(pred_pos[pred_pos==4])\n",
    "    n_correct_neg = len(pred_neg[pred_neg==0])\n",
    "    print(f'{m} : correct positive = {n_correct_pos}, correct_negative = {n_correct_neg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-likelihood",
   "metadata": {},
   "source": [
    "## TFIDF - measure recall rate \n",
    "With confidence interval of 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "attractive-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval of 95%\n",
      "---------------------------\n",
      "logit : mean recall between 0.80 and 0.82\n",
      "logit-3gram : mean recall between 0.80 and 0.82\n",
      "randomforest : mean recall between 0.63 and 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "n_trials = 20\n",
    "sample_size = 100\n",
    "samples = {m: [] for m,p in tfidfModels.items()}\n",
    "\n",
    "for n in range(n_trials):\n",
    "    dfSample = []\n",
    "    dfSample.append(dfTest[dfTest.sentiment==4].sample(n=sample_size//2))\n",
    "    dfSample.append(dfTest[dfTest.sentiment==0].sample(n=sample_size//2))\n",
    "    dfSample = pd.concat(dfSample)\n",
    "    for m,p in tfidfModels.items():\n",
    "        pred = p.predict(dfSample['text'])\n",
    "        expected = dfSample['sentiment']\n",
    "        samples[m].append(recall_score(expected, pred, pos_label=4))\n",
    "        \n",
    "# Calculate means with confidence interval of 95%\n",
    "z = 1.960\n",
    "print('Confidence interval of 95%')\n",
    "print('---------------------------')\n",
    "for m in tfidfModels.keys():\n",
    "    mean = np.mean(samples[m])\n",
    "    std = np.std(samples[m])\n",
    "    stderr = std/np.sqrt(sample_size)\n",
    "    margin = z * stderr\n",
    "    lb, ub = mean - margin, mean + margin\n",
    "    print(f'{m} : mean recall between {lb:.2f} and {ub:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-example",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "\n",
    "Using pretrained English wiki word embedding from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "funky-climate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000, 160000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfTrain), len(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "resident-laptop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words : 637598\n"
     ]
    }
   ],
   "source": [
    "num_distinct_words = len(dfClean['words'].explode().drop_duplicates())\n",
    "print(f'Number of distinct words : {num_distinct_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-mission",
   "metadata": {},
   "source": [
    "Use word embedding to vectorise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-virtue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-sweet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "basic-intervention",
   "metadata": {},
   "source": [
    "## Fasttext\n",
    "Using pretrained English wiki wordembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "endless-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-netscape",
   "metadata": {},
   "source": [
    "Preparation of fasttext K-fold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "russian-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "\n",
    "texts = dfTrain['text'].tolist()\n",
    "labels = dfTrain['sentiment'].tolist()\n",
    "chunksize = len(texts)//K\n",
    "ktest = []\n",
    "for k in range(K):\n",
    "    a = k*chunksize\n",
    "    b = (k+1)*chunksize\n",
    "    test_text = texts[a:b]\n",
    "    test_label = labels[a:b]\n",
    "    train_text = texts[:a] + texts[b:]\n",
    "    train_label = labels[:a] + labels[b:]\n",
    "    with open(f'fasttext_train_{k}.txt', 'w') as f:\n",
    "        for lbl, txt in zip(train_label, train_text):\n",
    "            f.write(f'__label__{lbl} {txt}\\n')\n",
    "    ktest.append([])\n",
    "    for lbl, txt in zip(test_label, test_text):\n",
    "        ktest[-1].append((lbl, txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hundred-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  288000 fasttext_test_0.txt\n",
      "  288000 fasttext_test_1.txt\n",
      "  288000 fasttext_test_2.txt\n",
      "  288000 fasttext_test_3.txt\n",
      "  288000 fasttext_test_4.txt\n",
      " 1152000 fasttext_train_0.txt\n",
      " 1152000 fasttext_train_1.txt\n",
      " 1152000 fasttext_train_2.txt\n",
      " 1152000 fasttext_train_3.txt\n",
      " 1152000 fasttext_train_4.txt\n",
      " 7200000 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l fasttext*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adopted-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 : \n",
      "Recall = 0.811, precision = 0.811394\n",
      "Fold 1 : \n",
      "Recall = 0.818, precision = 0.805819\n",
      "Fold 2 : \n",
      "Recall = 0.814, precision = 0.809776\n",
      "Fold 3 : \n",
      "Recall = 0.817, precision = 0.808384\n",
      "Fold 4 : \n",
      "Recall = 0.816, precision = 0.807780\n"
     ]
    }
   ],
   "source": [
    "# Cross validation K-Fold (manual way)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "for k in range(5):\n",
    "    print(f'Fold {k} : ')\n",
    "    mk = fasttext.train_supervised(\n",
    "        f'fasttext_train_{k}.txt', \n",
    "        wordNgrams=2, \n",
    "        lr=0.75)\n",
    "    labels = [f'__label__{lbl}' for lbl, t in ktest[k]]\n",
    "    pred = [mk.predict(t)[0][0] for lbl, t in ktest[k]]\n",
    "    rc = recall_score(labels, pred, pos_label='__label__4')\n",
    "    pc = precision_score(labels, pred, pos_label='__label__4')\n",
    "    print(f'\\rRecall = {rc:.3f}, precision = {pc:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-killing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
